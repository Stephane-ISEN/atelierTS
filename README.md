# SÃ©rie temporelle â€“ PrÃ©vision de consommation d'Ã©nergie (Brest MÃ©tropole)

Projet complet de **prÃ©vision de consommation Ã©lectrique** Ã  lâ€™aide dâ€™un modÃ¨le **LSTM multivariÃ©** avec suivi des expÃ©riences via **MLflow**.

Objectifs :

* Structurer un modÃ¨le prÃªt pour la production
* Versionner les entraÃ®nements
* Suivre les mÃ©triques
* Sauvegarder les modÃ¨les entraÃ®nÃ©s

---

# 1) PrÃ©parer le modÃ¨le pour la production

## ğŸ¯ Objectif

Passer dâ€™un notebook expÃ©rimental Ã  un script structurÃ©, rÃ©utilisable et exÃ©cutable en ligne de commande.

Un notebook est utile pour explorer.
Un script Python est indispensable pour :

* automatiser l'entraÃ®nement
* intÃ©grer MLflow
* dockeriser plus tard
* industrialiser le pipeline

---

## ğŸ“ Ã‰tape

Dans le rÃ©pertoire `./ml`, crÃ©er un fichier :

```
ml/modele.py
```

Y dÃ©placer le code du notebook `notebook_2_TS_multivarie` :

* prÃ©paration des donnÃ©es
* crÃ©ation des sÃ©quences temporelles
* dÃ©finition du modÃ¨le LSTM
* entraÃ®nement
* Ã©valuation

---

## ğŸ§  Bonne pratique

SÃ©parer le code en fonctions :

```python
prepare_datasets()
prepare_training_tensors()
build_lstm_model()
train_and_evaluate()
run_training()
```

Cela permet :

* une meilleure lisibilitÃ©
* des tests unitaires
* une rÃ©utilisation future (API, batch, etc.)

---

# 2) Lancer MLflow

## ğŸ¯ Objectif

Mettre en place un serveur de suivi des expÃ©riences.

MLflow permet de :

* enregistrer les hyperparamÃ¨tres
* stocker les mÃ©triques
* sauvegarder les modÃ¨les
* comparer les runs

---

## ğŸ“ CrÃ©er la structure locale

Ã€ la racine du projet :

```bash
mkdir -p mlruns
```

Cette structure contiendra :

```
mlruns/
â”œâ”€â”€ mlflow.db         â† base SQLite (tracking)
â””â”€â”€ 1/                â† numÃ©ro de run
```

---

## ğŸš€ Lancer le serveur MLflow

```bash
uv run mlflow server \
  --host 0.0.0.0 \
  --port 5000 \
  --backend-store-uri sqlite:///mlruns/mlflow.db \
  --default-artifact-root ./mlruns
```

### ğŸ” Explication des options

| Option                    | RÃ´le                                         |
| ------------------------- | -------------------------------------------- |
| `--backend-store-uri`     | Base SQLite qui stocke les runs et mÃ©triques |
| `--default-artifact-root` | Dossier oÃ¹ seront stockÃ©s les modÃ¨les        |
| `--host`                  | Permet d'accÃ©der depuis navigateur           |
| `--port`                  | Port dâ€™accÃ¨s au serveur                      |

---

## ğŸŒ AccÃ©der Ã  lâ€™interface

Ouvrir :

```
http://127.0.0.1:5000
```

Interface vide au dÃ©part â€” câ€™est normal.

---

# 3) IntÃ©grer MLflow dans le script Python

Dans `ml/modele.py`, ajouter les Ã©lÃ©ments suivants.

---

## ğŸ”— DÃ©finir le serveur MLflow

```python
mlflow.set_tracking_uri("http://127.0.0.1:5000")
```

### ğŸ¯ RÃ´le

Indique Ã  MLflow :

> OÃ¹ envoyer les runs.

Sans cette ligne, MLflow fonctionnerait en mode local.

---

## ğŸ—‚ DÃ©finir lâ€™expÃ©rience

```python
mlflow.set_experiment("brest_consumption_forecast")
```

### ğŸ¯ RÃ´le

* CrÃ©e lâ€™expÃ©rience si elle nâ€™existe pas
* Regroupe tous les entraÃ®nements sous un mÃªme projet

---

## â–¶ï¸ DÃ©marrer un run

```python
with mlflow.start_run(run_name="lstm_brest_consumption"):
```

### ğŸ¯ RÃ´le

Un run correspond Ã  **un entraÃ®nement complet**.

Tout ce qui est loggÃ© dans ce bloc :

* paramÃ¨tres
* mÃ©triques
* artefacts

sera attachÃ© Ã  ce run.

---

## âš™ï¸ Logger les hyperparamÃ¨tres

```python
mlflow.log_params({
    "window_size": window_size,
    "epochs": epochs,
    "batch_size": batch_size,
    "n_features": len(features),
})
```

### ğŸ¯ RÃ´le

Permet de :

* comprendre comment le modÃ¨le a Ã©tÃ© entraÃ®nÃ©
* reproduire les rÃ©sultats
* comparer plusieurs configurations

---

## ğŸ“Š Logger les mÃ©triques

```python
mlflow.log_metric("val_loss", final_val_loss)
mlflow.log_metrics(metrics)
```

### ğŸ¯ RÃ´le

Enregistrer les performances :

* `val_loss`
* `mae`
* `rmse`
* `mape`

Permet :

* comparaison visuelle entre runs
* sÃ©lection du meilleur modÃ¨le

---

## ğŸ’¾ Sauvegarder le modÃ¨le

```python
mlflow.keras.log_model(model, artifact_path="model")
```

### ğŸ¯ RÃ´le

Enregistre :

* architecture du modÃ¨le
* poids entraÃ®nÃ©s
* configuration

Le modÃ¨le est stockÃ© dans :

```
mlruns/artifacts/...
```

Il pourra Ãªtre :

* rechargÃ© plus tard
* servi via API
* versionnÃ©

---

# 4) Lancer l'entraÃ®nement

```bash
uv run ml/modele.py
```

### ğŸ¯ Ce quâ€™il se passe

1. Chargement des donnÃ©es
2. CrÃ©ation des sÃ©quences LSTM
3. EntraÃ®nement du modÃ¨le
4. Enregistrement dans MLflow
5. Sauvegarde du modÃ¨le

---

# 5) Ce que vous devriez voir dans l'interface

Dans MLflow UI :

## ğŸ“ Une expÃ©rience

```
brest_consumption_forecast
```

## â–¶ï¸ Un run

```
lstm_brest_consumption
```

## ğŸ“Œ ParamÃ¨tres

* `window_size`
* `epochs`
* `batch_size`
* `n_features`

## ğŸ“ˆ MÃ©triques

* `val_loss`
* `mae`
* `rmse`
* `mape`

## ğŸ“¦ Artefact

Un dossier :

```
model/
```

Contenant le modÃ¨le LSTM sauvegardÃ©.

---
