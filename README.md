# SÃ©rie temporelle consommation d'Ã©nergie

Projet de prÃ©vision de consommation Ã©lectrique (Brest MÃ©tropole) avec un modÃ¨le **LSTM multivariÃ©** et un service via **FastAPI**.

---

# CrÃ©er la structure

Ã€ la racine de ton projet :

```
project/
â”œâ”€â”€ api/
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ mlruns/
â””â”€â”€ ...
```

CrÃ©er le dossier :

```bash
mkdir api
touch api/main.py
```

---

# Rappel : comment MLflow sauvegarde un modÃ¨le

Quand tu fais :

```python
mlflow.keras.log_model(model, artifact_path="model")
```

MLflow crÃ©e un dossier :

```
mlruns/<experiment_id>/<run_id>/artifacts/model/
```

Ce dossier contient :

* MLmodel
* model.keras (ou SavedModel)
* requirements.txt
* python_env.yaml

---

# Charger le modÃ¨le

On utilise :

```python
mlflow.keras.load_model(path)
```

`path` doit pointer vers le dossier `model`.

Exemple :

```python
../mlruns/1/<RUN_ID>/artifacts/model
```

---

# Rappel : template dâ€™un endpoint FastAPI

```python
@app.get("/route")
def fonction(param: type):
    return {"clÃ©": "valeur"}
```

* `@app.get()` â†’ mÃ©thode HTTP
* `"/route"` â†’ URL
* paramÃ¨tres typÃ©s
* retour JSON automatique

---

# Rappel format des features

Ton modÃ¨le LSTM attend :

```
(batch_size, window_size, n_features)
```

Dans ton cas :

```
(1, 30, 19)
```

* 1 â†’ un seul exemple
* 30 â†’ fenÃªtre temporelle
* 19 â†’ nombre de variables

---

# Lancer lâ€™API

Ã€ la racine du projet :

```bash
uv run uvicorn api.main:app --reload
```

Tu dois voir :

```
Uvicorn running on http://127.0.0.1:8000
```

---

# Tester lâ€™API

Ouvre :

```
http://127.0.0.1:8000/docs
```

Interface Swagger automatique.

---

# ðŸ“¥ Format attendu de la donnÃ©e

Le endpoint attend :

```
/predict?d=YYYY-MM-DD
```

Exemple :

```
http://127.0.0.1:8000/predict?d=2026-02-12
```
