# atelierTS

Projet de pr√©vision de consommation √©lectrique (Brest M√©tropole) avec :
- un pipeline Python de pr√©paration + entra√Ænement,
- un suivi d'exp√©riences MLflow,
- une base **TimescaleDB (PostgreSQL)** pour stocker les donn√©es √©nerg√©tiques, m√©t√©o et pr√©dictions.

---

## Sommaire

1. [Architecture rapide](#architecture-rapide)
2. [Base de donn√©es TimescaleDB : vue d'ensemble](#base-de-donn√©es-timescaledb--vue-densemble)
3. [D√©tail du fichier `data/init.sql`](#d√©tail-du-fichier-datainitsql)
4. [D√©tail du code de connexion `bdd/connexion.py`](#d√©tail-du-code-de-connexion-bddconnexionpy)
5. [D√©tail du code ETL `bdd/etl.py`](#d√©tail-du-code-etl-bddetlpy)
6. [D√©tail du container Docker TimescaleDB](#d√©tail-du-container-docker-timescaledb)
7. [Variables d'environnement `.env`](#variables-denvironnement-env)
8. [Proc√©dure compl√®te de lancement](#proc√©dure-compl√®te-de-lancement)
9. [V√©rifications SQL utiles](#v√©rifications-sql-utiles)
10. [MLflow (rappel rapide)](#mlflow-rappel-rapide)

---

## Architecture rapide

Le code Python principal est r√©parti en 3 fichiers :

- `ml/data_preparation.py`
  - ingestion API √©lectricit√© + m√©t√©o,
  - fusion des jeux de donn√©es,
  - cr√©ation des features,
  - split train/test.

- `ml/model_preparation.py`
  - normalisation,
  - cr√©ation des s√©quences temporelles,
  - construction et entra√Ænement LSTM,
  - calcul des m√©triques.

- `ml/modele.py`
  - orchestration de bout en bout,
  - logging MLflow (params, metrics, model).

Partie base de donn√©es :
- `data/init.sql` : sch√©ma SQL + hypertables Timescale.
- `bdd/connexion.py` : classe de connexion PostgreSQL.
- `bdd/etl.py` : alimentation des tables de la BDD.

---

## Base de donn√©es TimescaleDB : vue d'ensemble

La base stocke 3 domaines m√©tiers :

1. **`consommation`**
   - s√©rie temporelle de la consommation √©lectrique (MW).
2. **`meteo`**
   - s√©rie temporelle m√©t√©o (temp√©rature, humidit√©, vent, rayonnement).
3. **`prediction`**
   - historique des valeurs r√©elles vs pr√©dites par un mod√®le (ici baseline `J-1`).

Ces 3 tables sont converties en **hypertables** TimescaleDB pour de meilleures performances temporelles.

---

## D√©tail du fichier `data/init.sql`

Le script SQL fait 4 choses importantes :

### 1) Active l'extension TimescaleDB
```sql
CREATE EXTENSION IF NOT EXISTS timescaledb;
```
Sans cette extension, les hypertables ne sont pas disponibles.

### 2) Cr√©e la table `consommation`
Champs principaux :
- `date_mesure TIMESTAMPTZ NOT NULL` : timestamp de mesure (cl√© temporelle),
- `consommation_mw DOUBLE PRECISION NOT NULL` : valeur de consommation,
- `source` et `cree_le` : tra√ßabilit√©,
- contrainte `UNIQUE(date_mesure)` : √©vite les doublons temporels.

### 3) Cr√©e la table `meteo`
Champs principaux :
- `date_mesure TIMESTAMPTZ NOT NULL`,
- `temperature_moyenne`, `humidite_relative`, `vitesse_vent`, `rayonnement_moyen`,
- `source` et `cree_le`,
- contrainte `UNIQUE(date_mesure)`.

### 4) Cr√©e la table `prediction`
Champs principaux :
- `date_prediction TIMESTAMPTZ NOT NULL`,
- `valeur_reelle`, `valeur_predite`,
- `modele` (ex: `baseline_j-1`),
- contrainte `UNIQUE(date_prediction, modele)` : une pr√©diction par timestamp et par mod√®le.

### 5) Convertit les tables en hypertables
```sql
SELECT create_hypertable('consommation', 'date_mesure', if_not_exists => TRUE);
SELECT create_hypertable('meteo', 'date_mesure', if_not_exists => TRUE);
SELECT create_hypertable('prediction', 'date_prediction', if_not_exists => TRUE);
```
Ce point est essentiel pour b√©n√©ficier des optimisations TimescaleDB sur les s√©ries temporelles.

---

## D√©tail du code de connexion `bdd/connexion.py`

Le module expose la classe `ConnexionBDD` avec 2 variables de classe :
- `bdd` : la connexion PostgreSQL,
- `curseur` : le curseur SQL r√©utilisable.

### `connexion()`
- charge les variables depuis `.env` via `load_dotenv()`,
- si une connexion existe d√©j√†, la renvoie (√©vite de recr√©er inutilement),
- sinon ouvre une connexion `psycopg2.connect(...)` avec :
  - `POSTGRES_HOST`
  - `POSTGRES_PORT`
  - `POSTGRES_DB`
  - `POSTGRES_USER`
  - `POSTGRES_PASSWORD`
- cr√©e et retourne `(bdd, curseur)`.

### `deconnexion()`
- ferme proprement le curseur puis la connexion,
- remet les variables de classe √† `None`.

Cette approche centralise la gestion de connexion dans un seul point.

---

## D√©tail du code ETL `bdd/etl.py`

L'ETL charge les donn√©es utiles au mod√®le dans les 3 tables.

### 1) `charger_consommation(cursor)`
- r√©cup√®re les donn√©es depuis `fetch_brest_electricity_data()`,
- renomme les colonnes vers le sch√©ma SQL,
- ins√®re dans `consommation` avec `ON CONFLICT (date_mesure) DO UPDATE`.

üëâ Effet : ETL **idempotent** (relancer le script met √† jour au lieu de dupliquer).

### 2) `charger_meteo(cursor)`
- r√©cup√®re les donn√©es m√©t√©o via `get_weather_data_brest(...)`,
- renomme les colonnes vers la table `meteo`,
- ins√®re/upsert avec `ON CONFLICT (date_mesure) DO UPDATE`.

### 3) `charger_prediction_baseline(cursor)`
- alimente `prediction` depuis `consommation`,
- calcule `valeur_predite` avec `LAG(consommation_mw, 1)` (baseline J-1),
- upsert avec conflit `(date_prediction, modele)`.

### 4) `executer_etl()`
- ouvre la connexion,
- ex√©cute les 3 chargements,
- `commit()` si tout va bien,
- `rollback()` en cas d'erreur,
- ferme la connexion dans tous les cas (`finally`).

---

## D√©tail du container Docker TimescaleDB

Le service `timescaledb` dans `docker-compose.yml` est configur√© ainsi :

- **image** : `timescale/timescaledb:latest-pg17`
- **env_file** : `.env`
- **ports** : `5432:5432`
- **volumes** :
  1. `./data/init.sql:/docker-entrypoint-initdb.d/init.sql`
     - ex√©cut√© automatiquement au premier d√©marrage de la base,
     - cr√©e les tables + hypertables.
  2. `./data/postgresql:/var/lib/postgresql/data`
     - conserve les donn√©es PostgreSQL localement (persistance).

‚ö†Ô∏è Note importante : les scripts de `docker-entrypoint-initdb.d` s'ex√©cutent seulement lors de l'initialisation d'un **nouveau** datadir. Si le dossier `./data/postgresql` contient d√©j√† une base initialis√©e, `init.sql` ne sera pas rejou√© automatiquement.

---

## Variables d'environnement `.env`

Cr√©er un fichier `.env` √† la racine (exemple) :

```env
POSTGRES_HOST=timescaledb
POSTGRES_PORT=5432
POSTGRES_DB=atelierts
POSTGRES_USER=atelierts
POSTGRES_PASSWORD=atelierts
```

`bdd/connexion.py` lit ces variables pour √©tablir la connexion.

---

## Proc√©dure compl√®te de lancement

### 1) Installer les d√©pendances Python
```bash
uv sync
```

### 2) Pr√©parer l'environnement
```bash
cp .env.example .env
# puis ajuster les valeurs si n√©cessaire
```

### 3) D√©marrer les services Docker
```bash
docker compose up -d
```

### 4) Charger la base avec l'ETL
```bash
uv run python bdd/etl.py
```

### 5) Lancer l'entra√Ænement + tracking MLflow
```bash
MLFLOW_TRACKING_URI=http://localhost:5000 uv run python ml/modele.py
```

### 6) Ouvrir l'interface MLflow
- http://localhost:5000

---

## V√©rifications SQL utiles

Une fois connect√© √† PostgreSQL, commandes utiles :

```sql
-- V√©rifier les tables
\dt

-- Voir le volume de donn√©es
SELECT COUNT(*) FROM consommation;
SELECT COUNT(*) FROM meteo;
SELECT COUNT(*) FROM prediction;

-- Aper√ßu rapide
SELECT * FROM consommation ORDER BY date_mesure DESC LIMIT 5;
SELECT * FROM meteo ORDER BY date_mesure DESC LIMIT 5;
SELECT * FROM prediction ORDER BY date_prediction DESC LIMIT 5;
```

---

## MLflow (rappel rapide)

Dans `ml/modele.py` :
- `mlflow.set_tracking_uri(...)`
- `mlflow.set_experiment("brest_consumption_forecast")`
- `mlflow.start_run(...)`
- `mlflow.log_params(...)`
- `mlflow.log_metrics(...)`
- `mlflow.keras.log_model(...)`

Dans l'UI MLflow, vous devez retrouver :
- l'exp√©rience `brest_consumption_forecast`,
- au moins un run `lstm_brest_consumption`,
- les param√®tres d'entra√Ænement,
- les m√©triques (MAE / RMSE / MAPE / val_loss),
- l'artefact `model`.
